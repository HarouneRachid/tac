{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381226b4",
   "metadata": {},
   "source": [
    "Importations des Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# D'autres importations\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de1a67",
   "metadata": {},
   "source": [
    "Les importations d'autres Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d069fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sn\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "import pandas as pd\n",
    "import re\n",
    "import operator\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c03de",
   "metadata": {},
   "source": [
    "## Le chemin de mes textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/txt/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74dd9dc",
   "metadata": {},
   "source": [
    "## Nous choisissons la décennie de 1010-1919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4771cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decenie = '1910'\n",
    "\n",
    "# Sélection des fichiers uniquement pour la décennie 1910-1919\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{decenie[:-1]}\" in f]\n",
    "\n",
    "# La varible Texts pour stocker le contenu de l'ensemble des fichiers sélectionnés\n",
    "\n",
    "texts = [open(data_path + f, \"r\", encoding=\"utf-8\").read() for f in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60045577",
   "metadata": {},
   "source": [
    "## Vectoriser les documents à l'aide de TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4490d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une fonction de pré-traitement\n",
    "def preprocessing(text, stem=True):\n",
    "    \"\"\" Tokenize text and remove punctuation \"\"\"\n",
    "    text = text.translate(string.punctuation)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962c90c",
   "metadata": {},
   "source": [
    "### Instancier le modèle TF-IDF avec ses arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35847d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=preprocessing,\n",
    "    stop_words=stopwords.words('french'),\n",
    "    max_df=0.5,\n",
    "    min_df=0.1,\n",
    "    lowercase=True)\n",
    "\n",
    "# Applications de vectorisation à mes textes\n",
    "\n",
    "tfidf_vectors = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Détail de la matrice\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77979b",
   "metadata": {},
   "source": [
    "### Imprimer le vecteur tf-IDF du premier document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb41d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    tfidf_vectors[0].toarray()[0],\n",
    "    index=vectorizer.get_feature_names_out()\n",
    "    ).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3e582",
   "metadata": {},
   "source": [
    "### Définissions d'un nombre de clusters et leurs applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 5\n",
    "\n",
    "# K-means\n",
    "km_model = KMeans(n_clusters=N_CLUSTERS)\n",
    "\n",
    "# Clusters\n",
    "\n",
    "clusters = km_model.fit_predict(tfidf_vectors)\n",
    "\n",
    "#  Clustering sur la liste de nos décennie\n",
    "clustering = collections.defaultdict(list)\n",
    "\n",
    "for idx, label in enumerate(clusters):\n",
    "    clustering[label].append(files[idx])\n",
    "\n",
    "\n",
    "# Affichage \n",
    "pprint(dict(clustering))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1d2da",
   "metadata": {},
   "source": [
    "### Réduction des vecteurs à 2 dimensions à l'aide de l'algorithme PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(tfidf_vectors.toarray())\n",
    "\n",
    "x_axis = reduced_vectors[:, 0]\n",
    "y_axis = reduced_vectors[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "scatter = plt.scatter(x_axis, y_axis, s=100, c=clusters)\n",
    "\n",
    "# Ajouter les centroïdes\n",
    "centroids = pca.transform(km_model.cluster_centers_)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],  marker = \"x\", s=100, linewidths = 2, color='black')\n",
    "\n",
    "# Ajouter la légende\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=set(clusters), title=\"Clusters\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
