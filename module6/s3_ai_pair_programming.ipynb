{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Pair Programming\n",
    "\n",
    "Dans ce notebook nous allons demander à une intelligence artificielle de générer du code Python pour réaliser des tâches de traitement automatique de corpus.\n",
    "\n",
    "Avant de commencer, choisissez un outil comme [Bard](https://bard.google.com/u/2/chat) ou [ChatGPT](https://chat.openai.com/) et créez un compte.\n",
    "\n",
    "Vous pouvez ensuite demander à l'outil de créer du code. Avant de commencer, n'hésitez pas à lire [cet article](https://exocoding.com/ai-code-generation/) qui détaille les **bonnes pratiques** pour créer des _prompts_ efficaces dans le cadre de la génération de code par l'intelligence artificielle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Algorithme simple en Python\n",
    "\n",
    "Demandez à l'IA de générer un code python qui lance un décompte du réveillon du Nouvel An. Le code doit imprimer les nombres de 10 à 0 avec un intervalle d'une seconde, puis imprimer \"Bonne année\" à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "Happy New Year!\n"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "\n",
    "import time\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Happy New Year!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Détection du sujet de la phrase\n",
    "\n",
    "Demandez à l'IA d'extraire le sujet dans une phrase.\n",
    "Demandez ensuite de générer le code Python qui réalise cette tâche et testez le ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entités nommmées liées à Wikidata\n",
    "\n",
    "Demandez à l'IA d'extraire les entités nommées d'un texte en français, et de les lier à un identifiant wikidata.\n",
    "Demandez ensuite à l'IA de générer le code Python pour réaliser cette tâche et testez le ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement EntityLinker (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for EntityLinker\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install EntityLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy_entity_linker'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Votre code ici\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy_entity_linker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntityLinker\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Charge un modèle spaCy pour le français\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# (assure-toi d'avoir installé un modèle français, par exemple \"fr_core_news_md\" ou \"fr_core_news_sm\")\u001b[39;00m\n\u001b[32m      8\u001b[39m nlp = spacy.load(\u001b[33m\"\u001b[39m\u001b[33mfr_core_news_md\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy_entity_linker'"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "\n",
    "import spacy\n",
    "from spacy_entity_linker import EntityLinker\n",
    "\n",
    "# Charge un modèle spaCy pour le français\n",
    "# (assure-toi d'avoir installé un modèle français, par exemple \"fr_core_news_md\" ou \"fr_core_news_sm\")\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Ajoute le pipeline \"entityLinker\"\n",
    "linker = EntityLinker()\n",
    "nlp.add_pipe(\"entityLinker\", last=True)\n",
    "\n",
    "# Exemple de texte\n",
    "texte = (\n",
    "    \"Ces deux jeux de données présentent une ontologie sur plusieurs niveaux \"\n",
    "    \"avec un nombre important de classes, de tokens et d’entités. À la suite de cette étape d’identification, \"\n",
    "    \"nous avons retenu celui qui présentait le meilleur score d’accord inter-annotateur (Kappa de Cohen à 0.87) : DWIE. \"\n",
    "    \"DWIE est annoté avec 169 classes organisées dans une taxonomie à 4 niveaux.\"\n",
    ")\n",
    "\n",
    "# Traite le texte\n",
    "doc = nlp(texte)\n",
    "\n",
    "# Récupère les entités liées\n",
    "linked = doc._.linkedEntities\n",
    "\n",
    "# Affiche chaque entité trouvée avec le span, le label Wikidata (QID), et l’URL\n",
    "for entity in linked:\n",
    "    span = entity.get_span(doc)\n",
    "    print(f\"Texte reconnu : «{span.text}»\")\n",
    "    print(f\" - Wikidata ID : {entity.get_id()}\")\n",
    "    print(f\" - Label : {entity.get_label()}\")\n",
    "    print(f\" - Description : {entity.get_description()}\")\n",
    "    print(f\" - URL : {entity.get_url()}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. A vous de jouer\n",
    "\n",
    "Pensez à une analyse que vous voudriez faire sur un texte. Demandez à l'IA de générer un code python qui réalise cette analyse et testez le ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy_entity_linker'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Votre code ici\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy_entity_linker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntityLinker\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 1. Charger le modèle français\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m nlp = spacy.load(\u001b[33m\"\u001b[39m\u001b[33mfr_core_news_md\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy_entity_linker'"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "\n",
    "import spacy\n",
    "from spacy_entity_linker import EntityLinker\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Charger le modèle français\n",
    "# -----------------------------\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Ajouter le linker Wikidata\n",
    "# -----------------------------\n",
    "linker = EntityLinker()\n",
    "nlp.add_pipe(\"entityLinker\", last=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Texte à analyser\n",
    "# -----------------------------\n",
    "texte = \"\"\"\n",
    "D’une part, ces évaluations mesurent l’impact de chaque méthode d’alignement sur le jeu de données produit ; \n",
    "l’objectif ici est d’évaluer à quel point les transferts de classes de la version anglaise vers la version \n",
    "traduite ont été correctement effectués. D’autre part, elles donnent une indication sur la qualité globale \n",
    "du jeu de données produit.\n",
    "Pour chacun des trois jeux de données, un échantillon de 1000 tokens a été annoté par chacun des sept experts \n",
    "(chaque expert a annoté des échantillons différents) en respectant la typologie d’erreurs présentée dans le \n",
    "Tableau 3. Au total, 298 phrases ont été évaluées.\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Analyse NER + Linking\n",
    "# -----------------------------\n",
    "doc = nlp(texte)\n",
    "\n",
    "print(\"\\n=== ENTITÉS NOMMÉES DÉTECTÉES ===\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"- {ent.text}  ({ent.label_})\")\n",
    "\n",
    "print(\"\\n=== LIENS WIKIDATA (si disponibles) ===\")\n",
    "linked = doc._.linkedEntities\n",
    "\n",
    "for entity in linked:\n",
    "    span = entity.get_span(doc)\n",
    "    print(f\"\\nTexte : «{span.text}»\")\n",
    "    print(f\" - Wikidata ID : {entity.get_id()}\")\n",
    "    print(f\" - Label : {entity.get_label()}\")\n",
    "    print(f\" - Description : {entity.get_description()}\")\n",
    "    print(f\" - URL : {entity.get_url()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pour aller plus loin...\n",
    "\n",
    "En tant qu'étudiant ULB vous avez accès gratuitement au [Github student pack](https://education.github.com/pack). Ce pack vous donne permet d'utiliser [Github copilot](https://github.com/features/copilot), un outil d'auto-complétion de code grâce à l'intelligence artificielle. Ceci peut être très utile si vous voulez réaliser des tâches complexes sans être un expert en python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTITÉS ===\n",
      "- Tableau 3 (MISC)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M-STIC/Traitement Automatique de Corpus/tac/.venv/lib/python3.11/site-packages/requests/models.py:976\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ment.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ment.label_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Recherche Wikidata\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m info = \u001b[43mwikidata_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43ment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   → Wikidata : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mwikidata_search\u001b[39m\u001b[34m(ent_text)\u001b[39m\n\u001b[32m      9\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.wikidata.org/w/api.php\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m params = {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwbsearchentities\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m: ent_text\n\u001b[32m     15\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m r \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r[\u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m:\n\u001b[32m     19\u001b[39m     best = r[\u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M-STIC/Traitement Automatique de Corpus/tac/.venv/lib/python3.11/site-packages/requests/models.py:980\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import requests\n",
    "\n",
    "# Charger un modèle français\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Fonction pour interroger Wikidata\n",
    "def wikidata_search(ent_text):\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"language\": \"fr\",\n",
    "        \"format\": \"json\",\n",
    "        \"search\": ent_text\n",
    "    }\n",
    "    r = requests.get(url, params=params).json()\n",
    "    \n",
    "    if \"search\" in r and len(r[\"search\"]) > 0:\n",
    "        best = r[\"search\"][0]\n",
    "        return {\n",
    "            \"id\": best[\"id\"],\n",
    "            \"label\": best.get(\"label\", \"\"),\n",
    "            \"description\": best.get(\"description\", \"\")\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Texte à analyser\n",
    "texte = \"\"\"\n",
    "D’une part, ces évaluations mesurent l’impact de chaque méthode d’alignement sur le jeu de données produit ;\n",
    "l’objectif ici est d’évaluer à quel point les transferts de classes de la version anglaise vers la version traduite\n",
    "ont été correctement effectués. D’autre part, elles donnent une indication sur la qualité globale du jeu de\n",
    "données produit. Pour chacun des trois jeux de données, un échantillon de 1000 tokens a été annoté par chacun\n",
    "des sept experts (chaque expert a annoté des échantillons différents) en respectant la typologie d’erreurs\n",
    "présentée dans le Tableau 3. Au total, 298 phrases ont été évaluées.\n",
    "\"\"\"\n",
    "\n",
    "# Analyse spaCy\n",
    "doc = nlp(texte)\n",
    "\n",
    "print(\"=== ENTITÉS ===\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"- {ent.text} ({ent.label_})\")\n",
    "    \n",
    "    # Recherche Wikidata\n",
    "    info = wikidata_search(ent.text)\n",
    "    if info:\n",
    "        print(f\"   → Wikidata : {info['id']}\")\n",
    "        print(f\"     Label : {info['label']}\")\n",
    "        print(f\"     Description : {info['description']}\")\n",
    "    else:\n",
    "        print(\"   → Aucune correspondance trouvée\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
